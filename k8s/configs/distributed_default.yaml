project:
  name: "fine_tune_research"

dataset:
  type: "hf"
  name: "sadmoseby/sample-function-call"
  format: "text"

model:
  base:
    type: "hf"
    name: "meta-llama/Llama-2-7b-hf"
  output:
    type: "hf"
    name: "sadmoseby/llama-2-hf-function-call"

training:
  trainer:
    packing: True
    max_seq_length: 512
    use_flash_attn: True
  sft:
    per_device_train_batch_size: 10
    per_device_eval_batch_size: 10
    bf16: True
    learning_rate: 0.0002
    lr_scheduler_type: "cosine"
    warmup_ratio: 0.1
    max_steps: 500
    save_strategy: "epoch"
    optim: "paged_adamw_32bit"
    max_grad_norm: 0.3
    gradient_accumulation_steps: 4
    gradient_checkpointing: True
    gradient_checkpointing_kwargs:
      use_reentrant: False
    logging_steps: 10
  other:
    freeze_embed: True
    n_freeze: 24
